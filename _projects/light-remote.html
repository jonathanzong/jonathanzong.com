---
active_section: projects
---

<style>
p {
  margin: 1em auto;
}
</style>

<p>
  <img src="/images/projects/light-remote/P1270014.jpg" />
</p>

<p>
  <strong>Light Remote</strong> is an AR spatial interface for the direct manipulation of theatrical lighting using motion tracking.
</p>

<p>
  When I started using the Studiolab at Princeton, I saw an opportunity in the fact that the motion capture and theatre lighting were coincidentally co-located. I created a motion tracking wearable out of capture dots and a wristband, and wrote a program in Matlab that calculates intersections between the position of the lights in the room and a 15 degree cone in the direction the wristband is pointing. Any intersections would be sent over OSC to the EOS light board, which would control the lights. Adding a wireless mouse as a peripheral enables more input dimensions like hue and brightness.
</p>

<p>
  The motion capture Matlab script can be found in this <a href="https://gist.github.com/jonathanzong/ccff530a3daacd87d943739e533ea492" target="_blank">Github gist</a>.
</p>

<p>
  <img src="/images/projects/light-remote/P1270017.jpg" />
</p>
